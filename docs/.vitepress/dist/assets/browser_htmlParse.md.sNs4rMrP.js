import{_ as l,o as t,c as e,R as a}from"./chunks/framework.mPPLtEmG.js";const i="/WoodBellNote/assets/htmlParse.-OPvTkYu.png",p=JSON.parse('{"title":"HTML 解析的大致过程","description":"","frontmatter":{},"headers":[],"relativePath":"browser/htmlParse.md","filePath":"browser/htmlParse.md"}'),o={name:"browser/htmlParse.md"},r=a('<h1 id="html-解析的大致过程" tabindex="-1">HTML 解析的大致过程 <a class="header-anchor" href="#html-解析的大致过程" aria-label="Permalink to &quot;HTML 解析的大致过程&quot;">​</a></h1><h1 id="先抄一张图" tabindex="-1">先抄一张图 <a class="header-anchor" href="#先抄一张图" aria-label="Permalink to &quot;先抄一张图&quot;">​</a></h1><p>whatwg 的 html 文档中有关 html 解析过程的说明 <img src="'+i+'" alt="HTML Parsing"></p><h2 id="粗线条的说明" tabindex="-1">粗线条的说明 <a class="header-anchor" href="#粗线条的说明" aria-label="Permalink to &quot;粗线条的说明&quot;">​</a></h2><ul><li>网络响应传回 html 文件</li><li>浏览器将这些二进制字节流按照设定的 字符编码（character encoding） 方式来解码，最后形成实际的字符传给分词器 <ul><li>其中似乎有一个字符编码嗅探算法，同时用字符编码和 confidence 值来判断是不是要更改编码方式</li></ul></li><li>在进入分词器之前，这些字节流还需要进行一次预处理/标准化来替换其中一些字符 <ul><li>比如 utf-lf 会替换所有的 utf-cr</li><li>utf null 会出于安全问题被替换为 utf fffd</li></ul></li><li>标准化后的数据会进入分词阶段 <ul><li>用大概 80 几个状态机来处理所有的 html 文本内容</li><li>将连续的字节流拆分为一系列独立 tokne，并将配对好的 tokne 返回字节流</li></ul></li><li>依据分词的 html 内容进行 tree construction <ul><li>这一阶段会和 document dom 相关联</li><li>过程中会不断修改和扩充这个 dom 的内容</li><li>最后返回这个完全体的 dom</li></ul></li><li>最后结果是返回一个 document dom 对象</li></ul>',5),s=[r];function n(c,h,d,m,u,_){return t(),e("div",null,s)}const P=l(o,[["render",n]]);export{p as __pageData,P as default};
